```{post} Jan 03, 2025
:tags: databases, llms
:category: link-blog
```

## Databases

I really enjoyed this post from **Andy Pavlo**, [Databases in 2024: A
Year in
Review](https://www.cs.cmu.edu/~pavlo/blog/2025/01/2024-databases-retrospective.html).
I've been looking at DuckDB for a few use cases, and always love the
ability to add things to Postgres instead of spinning up a new service!

> In the same way that Postgres is the default choice for anyone
> starting a new operational database, DuckDB has entered the zeitgeist
> as the default choice for someone wanting to run analytical queries on
> their data. Pandas previously held DuckDB\'s crowned position. Given
> DuckDB\'s insane portability, there are several efforts to stick it
> inside existing DBMSs that do not have great support for OLAP
> workloads. This year, we saw the release of four different extensions
> to stick DuckDB up inside Postgres.

## Large Language Models

This post from **Simon Willison**, [Things we learned about LLMs in
2024](https://simonwillison.net/2024/Dec/31/llms-in-2024/) is another
great overview. I've been following his blog for years, since we hang
out in similar Python circles, and it's been great to see the traction
he's gotten by being a solid experimenter in the AI ecosystem.

> A welcome result of the increased efficiency of the models---both the
> hosted ones and the ones I can run locally---is that the energy usage
> and environmental impact of running a prompt has dropped enormously
> over the past couple of years.
>
> \[...\]
>
> For less efficient models I find it useful to compare their energy
> usage to commercial flights. The largest Llama 3 model cost about the
> same as a single digit number of fully loaded passenger flights from
> New York to London. That's certainly not nothing, but once trained
> that model can be used by millions of people at no extra training
> cost.
